{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "44f907a9-05d5-43f3-9360-940f7e1502f2",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\cronu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
            "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
            "C:\\Users\\cronu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
            "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
            "C:\\Users\\cronu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
            "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
            "C:\\Users\\cronu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
            "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
            "C:\\Users\\cronu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
            "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
          ]
        },
        {
          "ename": "InvalidIndexError",
          "evalue": "Reindexing only valid with uniquely valued Index objects",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 80\u001b[0m\n\u001b[0;32m     77\u001b[0m             sheet\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m汇总日期\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m规模计算日期\u001b[39m\u001b[38;5;124m'\u001b[39m}, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     78\u001b[0m         nv_dfs\u001b[38;5;241m.\u001b[39mappend(sheet)\n\u001b[1;32m---> 80\u001b[0m df_nv_all \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnv_dfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# 处理净值表中的日期格式\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m规模计算日期\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df_nv_all\u001b[38;5;241m.\u001b[39mcolumns:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:395\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    383\u001b[0m     objs,\n\u001b[0;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    393\u001b[0m )\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:680\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    678\u001b[0m         obj_labels \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39maxes[\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m ax]\n\u001b[0;32m    679\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_labels\u001b[38;5;241m.\u001b[39mequals(obj_labels):\n\u001b[1;32m--> 680\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m \u001b[43mobj_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    682\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[0;32m    684\u001b[0m new_data \u001b[38;5;241m=\u001b[39m concatenate_managers(\n\u001b[0;32m    685\u001b[0m     mgrs_indexers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_axes, concat_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[0;32m    686\u001b[0m )\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3885\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   3882\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_method(method, limit, tolerance)\n\u001b[0;32m   3884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique:\n\u001b[1;32m-> 3885\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_requires_unique_msg)\n\u001b[0;32m   3887\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   3888\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp)\n",
            "\u001b[1;31mInvalidIndexError\u001b[0m: Reindexing only valid with uniquely valued Index objects"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "def parse_mixed_date(series):\n",
        "    \"\"\"Parse various date formats including Excel serials and yyyymmdd strings.\"\"\"\n",
        "    import re\n",
        "\n",
        "    def convert(value):\n",
        "        if pd.isna(value) or value == \"\":\n",
        "            return pd.NaT\n",
        "\n",
        "        text = str(value).strip()\n",
        "\n",
        "        if re.fullmatch(r\"\\d{8}\", text):\n",
        "            try:\n",
        "                return pd.to_datetime(text, format=\"%Y%m%d\")\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        if re.fullmatch(r\"\\d{4,6}\", text):\n",
        "            try:\n",
        "                return pd.to_datetime(float(text), unit=\"D\", origin=\"1899-12-30\")\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        try:\n",
        "            return pd.to_datetime(text)\n",
        "        except Exception:\n",
        "            return pd.NaT\n",
        "\n",
        "    return series.apply(convert).dt.floor(\"D\")\n",
        "\n",
        "# ========== 路径和文件识别 ==========\n",
        "root_path = os.path.dirname(os.path.abspath(__file__)) if '__file__' in globals() else \"./\"\n",
        "files = [f for f in os.listdir(root_path) if f.endswith(('.xls', '.xlsx')) and not f.startswith('~$')]\n",
        "\n",
        "product_file = next((f for f in files if '产品查询' in f), None)\n",
        "nv_files = [f for f in files if '产品查询' not in f]\n",
        "\n",
        "assert product_file, \"未找到包含“产品查询”的文件\"\n",
        "assert nv_files, \"未找到净值数据文件\"\n",
        "\n",
        "# ========== 读取产品查询表 ==========\n",
        "df_product = pd.read_excel(os.path.join(root_path, product_file), sheet_name=\"产品列表\", header=8)\n",
        "df_product.columns = df_product.columns.str.strip()\n",
        "\n",
        "df_product = df_product.rename(columns={\n",
        "    '发行机构销售代码': '产品代码',\n",
        "    '首次募集开始日期': '募集开始日期',\n",
        "    '首次募集结束日期': '募集结束日期',\n",
        "    '最早实际成立日期': '成立日',\n",
        "    '最早实际结束日期': '到期日'\n",
        "})\n",
        "\n",
        "# 处理产品表中的日期格式\n",
        "for _col in ['募集开始日期', '募集结束日期', '成立日', '到期日']:\n",
        "    if _col in df_product.columns:\n",
        "        df_product[_col] = parse_mixed_date(df_product[_col])\n",
        "\n",
        "# ========== 读取净值数据 ==========\n",
        "nv_dfs = []\n",
        "for f in nv_files:\n",
        "    path = os.path.join(root_path, f)\n",
        "    df_dict = pd.read_excel(path, sheet_name=None, header=2)\n",
        "    for sheet in df_dict.values():\n",
        "        sheet.columns = sheet.columns.str.strip()\n",
        "        sheet = sheet.loc[:, ~sheet.columns.duplicated()]\n",
        "        # 标准化字段名\n",
        "        if '产品代码' not in sheet.columns:\n",
        "            sheet.rename(columns={sheet.columns[0]: '产品代码'}, inplace=True)\n",
        "        if '最新单位净值' not in sheet.columns:\n",
        "            alt = [col for col in sheet.columns if '单位净值' in col]\n",
        "            if alt:\n",
        "                sheet.rename(columns={alt[0]: '最新单位净值'}, inplace=True)\n",
        "        if '汇总日期' in sheet.columns:\n",
        "            sheet.rename(columns={'汇总日期': '规模计算日期'}, inplace=True)\n",
        "        nv_dfs.append(sheet)\n",
        "\n",
        "df_nv_all = pd.concat(nv_dfs, ignore_index=True)\n",
        "\n",
        "# 处理净值表中的日期格式\n",
        "if '规模计算日期' in df_nv_all.columns:\n",
        "    df_nv_all['规模计算日期'] = parse_mixed_date(df_nv_all['规模计算日期'])\n",
        "\n",
        "# ========== 合并产品数据 ==========\n",
        "df_merged = pd.merge(df_nv_all, df_product, how='left', on='产品代码')\n",
        "# 保留净值表字段，重命名为标准名称\n",
        "df_merged.rename(columns={\n",
        "    '最新单位净值_x': '最新单位净值',\n",
        "    '最新单位净值_y': '备用单位净值',\n",
        "}, inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "# ========== 字段清理和日期转换 ==========\n",
        "for _col in ['规模计算日期', '成立日', '募集开始日期', '募集结束日期', '到期日']:\n",
        "    if _col in df_merged.columns:\n",
        "        df_merged[_col] = parse_mixed_date(df_merged[_col])\n",
        "\n",
        "# ========== 年化收益率计算 ==========\n",
        "def calc_annualized_return(row):\n",
        "    try:\n",
        "        days = (row['规模计算日期'] - row['成立日']).days\n",
        "        if days <= 0 or pd.isna(row['最新单位净值']):\n",
        "            return None\n",
        "        return (pow(float(row['最新单位净值']), 365 / days) - 1) * 100\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "df_merged['成立以来年化收益率（%）'] = df_merged.apply(calc_annualized_return, axis=1)\n",
        "df_merged['最新累计净值'] = df_merged['最新单位净值']\n",
        "\n",
        "# ========== 披露日期识别 ==========\n",
        "def get_latest_disclosure_dates(df):\n",
        "    result = {}\n",
        "    for code, group in df.groupby('产品代码'):\n",
        "        group_sorted = group.sort_values('规模计算日期')\n",
        "        net = group_sorted['最新单位净值'].fillna(method='ffill')\n",
        "        changes = net != net.shift(1)\n",
        "        changes.iloc[0] = True\n",
        "        changed_dates = group_sorted.loc[changes, '规模计算日期']\n",
        "        if not changed_dates.empty:\n",
        "            result[code] = changed_dates.iloc[-1]\n",
        "    return result\n",
        "\n",
        "disclosure_dates = get_latest_disclosure_dates(df_nv_all)\n",
        "\n",
        "def determine_latest_nav_date(row):\n",
        "    if '开放式' in str(row.get('运作模式', '')):\n",
        "        return row['规模计算日期']\n",
        "    return disclosure_dates.get(row['产品代码'], row['规模计算日期'])\n",
        "\n",
        "df_merged['最新净值日期'] = df_merged.apply(determine_latest_nav_date, axis=1)\n",
        "\n",
        "# ========== 字段选择与重命名 ==========\n",
        "final_columns = [\n",
        "    '规模计算日期', '产品代码', '产品名称', '运作模式', '开放类型', '风险等级', '投资性质二级',\n",
        "    '募集开始日期', '募集结束日期', '成立日', '到期日', '投资周期（天）',\n",
        "    '业绩比较基准（%）', '当前业绩比较基准下限（%）', '当前业绩比较基准上限（%）',\n",
        "    '最新销售费(%)', '最新固定管理费(%)',\n",
        "    '实际募集总规模', '折合人民币实际募集总规模', '产品市值', '产品市值',\n",
        "    '成立以来年化收益率（%）', '最新单位净值', '最新累计净值', '最新净值日期',\n",
        "    '销售商名称', '销售对象', '产品系列', '募集方式', '募集币种'\n",
        "]\n",
        "df_merged = df_merged[final_columns]\n",
        "\n",
        "df_merged.columns = [\n",
        "    '规模计算日期', '产品代码（发行机构销售代码）', '产品名称', '运作模式', '开放类型', '风险等级', '投资类型（投资性质二级）',\n",
        "    '募集开始日期', '募集结束日期', '成立日', '到期日', '期限（天）',\n",
        "    '业绩比较基准（%）', '当前业绩比较基准下限（%）', '当前业绩比较基准上限（%）',\n",
        "    '最新销售费（%）', '最新固定管理费（%）',\n",
        "    '实际募集总规模（亿元）', '折合人民币实际募集总规模（亿元）', '计算日存续规模（亿元）', '折合人民币计算日存续规模（亿元）',\n",
        "    '成立以来年化收益率（%）', '最新单位净值', '最新累计净值', '最新净值日期',\n",
        "    '代销机构', '销售对象', '产品系列', '募集方式', '募集币种'\n",
        "]\n",
        "\n",
        "# 按照字段名将规模相关数据转换为亿元\n",
        "for _col in ['实际募集总规模（亿元）', '折合人民币实际募集总规模（亿元）', '计算日存续规模（亿元）', '折合人民币计算日存续规模（亿元）']:\n",
        "    if _col in df_merged.columns:\n",
        "        df_merged[_col] = pd.to_numeric(df_merged[_col], errors='coerce') / 1e8\n",
        "\n",
        "# ========== 按年份输出 ==========\n",
        "df_merged['年份'] = df_merged['规模计算日期'].dt.year\n",
        "year_groups = df_merged.groupby('年份')\n",
        "\n",
        "# 日期统一为 yyyy-mm-dd 格式\n",
        "for _col in ['规模计算日期', '募集开始日期', '募集结束日期', '成立日', '到期日', '最新净值日期']:\n",
        "    if _col in df_merged.columns:\n",
        "        df_merged[_col] = df_merged[_col].dt.strftime('%Y-%m-%d')\n",
        "\n",
        "output_path = os.path.join(root_path, \"产品达标分析结果.xlsx\")\n",
        "with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
        "    if len(year_groups) == 1:\n",
        "        df_merged.drop(columns='年份').to_excel(writer, sheet_name=\"产品达标分析结果\", index=False)\n",
        "    else:\n",
        "        for year, group in year_groups:\n",
        "            group.drop(columns='年份').to_excel(writer, sheet_name=str(year), index=False)\n",
        "\n",
        "print(f\"✅ 分析结果已保存至：{output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "266e485c-868f-4edd-9b85-33253e3bc4e6",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8200f86-e4da-492f-b853-3402d10a2fd7",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
